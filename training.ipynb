{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f51224f7-86dd-42c7-ab88-bf120b6e7afe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /home/jupyter/.kaggle/kaggle.json'\n",
      "Downloading hmfeatureszipfin.zip to /home/jupyter\n",
      "100%|█████████████████████████████████████▉| 9.55G/9.58G [01:22<00:00, 89.1MB/s]\n",
      "100%|███████████████████████████████████████| 9.58G/9.58G [01:22<00:00, 125MB/s]\n"
     ]
    }
   ],
   "source": [
    "!kaggle datasets download muennighoff/hmfeatureszipfin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92dc8a7d-9ef0-4e43-9cfe-e76352726b79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-05-05 19:05:08--  https://convaisharables.blob.core.windows.net/uniter/pretrained/uniter-large.pt\n",
      "Resolving convaisharables.blob.core.windows.net (convaisharables.blob.core.windows.net)... 13.77.184.64\n",
      "Connecting to convaisharables.blob.core.windows.net (convaisharables.blob.core.windows.net)|13.77.184.64|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 744701865 (710M) [application/octet-stream]\n",
      "Saving to: ‘uniter-large.pt’\n",
      "\n",
      "uniter-large.pt     100%[===================>] 710.20M  26.9MB/s    in 26s     \n",
      "\n",
      "2022-05-05 19:05:34 (27.4 MB/s) - ‘uniter-large.pt’ saved [744701865/744701865]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://convaisharables.blob.core.windows.net/uniter/pretrained/uniter-large.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be349aee-977c-49e7-8b87-058f0c0c4ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mv uniter-large.pt ./vilio/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1184fa49-7f0e-461b-aaf3-06126215c9ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  hmfeatureszipfin.zip\n",
      "  inflating: detectron.lmdb/data.mdb  \n",
      "  inflating: detectron.lmdb/lock.mdb  \n"
     ]
    }
   ],
   "source": [
    "!unzip hmfeatureszipfin.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c1f31c5-3e3e-4b26-82a2-68bf06bbd0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mv detectron.lmdb ./vilio/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7caca642-5513-4d82-991e-6a5385ae055d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp ./vilio/py-bottom-up-attention/data/hm_vgattr3636.tsv ./vilio/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f7f58a54-46b9-4718-a8a3-24b741d165a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp -r ./vilio/py-bottom-up-attention/data/img ./vilio/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "312524c6-8ecd-4c4d-a98f-7fc86006176a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp ./vilio/py-bottom-up-attention/data/train.jsonl ./vilio/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "519fcf30-b860-4ecb-81f9-37ec474e438f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cp data for ernie-vil\n",
    "!cp ./vilio/py-bottom-up-attention/data/hm_vgattr3636.tsv ./vilio/ernie-vil/data/hm\n",
    "!cp -r ./vilio/py-bottom-up-attention/data/img ./vilio/ernie-vil/data/hm\n",
    "!cp ./vilio/py-bottom-up-attention/data/train.jsonl ./vilio/ernie-vil/data/hm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4835af28-473a-4d68-bdc4-238078e87f01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk==3.2.4\n",
      "  Using cached nltk-3.2.4.tar.gz (1.2 MB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 2)) (1.18.1)\n",
      "Collecting scipy==1.2.1\n",
      "  Using cached scipy-1.2.1-cp37-cp37m-manylinux1_x86_64.whl (24.8 MB)\n",
      "Collecting six==1.11.0\n",
      "  Using cached six-1.11.0-py2.py3-none-any.whl (10 kB)\n",
      "Collecting json_lines==0.5.0\n",
      "  Using cached json_lines-0.5.0-py2.py3-none-any.whl (6.8 kB)\n",
      "Collecting lmdb==0.97\n",
      "  Using cached lmdb-0.97.tar.gz (869 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting opencv-python==3.4.2.17\n",
      "  Using cached opencv_python-3.4.2.17-cp37-cp37m-manylinux1_x86_64.whl (25.0 MB)\n",
      "Collecting paddlepaddle-gpu==1.8.3.post97\n",
      "  Using cached paddlepaddle_gpu-1.8.3.post97-cp37-cp37m-manylinux1_x86_64.whl (404.9 MB)\n",
      "Collecting pandas==1.0.5\n",
      "  Using cached pandas-1.0.5-cp37-cp37m-manylinux1_x86_64.whl (10.1 MB)\n",
      "Requirement already satisfied: ImageHash==4.1.0 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 10)) (4.1.0)\n",
      "Requirement already satisfied: matplotlib==3.2.1 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 11)) (3.2.1)\n",
      "Requirement already satisfied: Pillow==8.0.1 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 12)) (8.0.1)\n",
      "Requirement already satisfied: scikit_learn==0.23.2 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 13)) (0.23.2)\n",
      "Requirement already satisfied: requests>=2.20.0 in /opt/conda/lib/python3.7/site-packages (from paddlepaddle-gpu==1.8.3.post97->-r requirements.txt (line 8)) (2.23.0)\n",
      "Requirement already satisfied: protobuf>=3.1.0 in /opt/conda/lib/python3.7/site-packages (from paddlepaddle-gpu==1.8.3.post97->-r requirements.txt (line 8)) (3.19.4)\n",
      "Collecting objgraph\n",
      "  Downloading objgraph-3.5.0-py2.py3-none-any.whl (17 kB)\n",
      "Collecting pathlib\n",
      "  Downloading pathlib-1.0.1-py3-none-any.whl (14 kB)\n",
      "Collecting funcsigs\n",
      "  Downloading funcsigs-1.0.2-py2.py3-none-any.whl (17 kB)\n",
      "Collecting astor\n",
      "  Downloading astor-0.8.1-py2.py3-none-any.whl (27 kB)\n",
      "Requirement already satisfied: gast>=0.3.3 in /opt/conda/lib/python3.7/site-packages (from paddlepaddle-gpu==1.8.3.post97->-r requirements.txt (line 8)) (0.3.3)\n",
      "Collecting rarfile\n",
      "  Downloading rarfile-4.0-py3-none-any.whl (28 kB)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.7/site-packages (from paddlepaddle-gpu==1.8.3.post97->-r requirements.txt (line 8)) (5.3.1)\n",
      "Collecting graphviz\n",
      "  Downloading graphviz-0.20-py3-none-any.whl (46 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.0/47.0 KB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: prettytable in /opt/conda/lib/python3.7/site-packages (from paddlepaddle-gpu==1.8.3.post97->-r requirements.txt (line 8)) (3.2.0)\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.7/site-packages (from paddlepaddle-gpu==1.8.3.post97->-r requirements.txt (line 8)) (5.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /opt/conda/lib/python3.7/site-packages (from pandas==1.0.5->-r requirements.txt (line 9)) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.2 in /opt/conda/lib/python3.7/site-packages (from pandas==1.0.5->-r requirements.txt (line 9)) (2021.3)\n",
      "Requirement already satisfied: PyWavelets in /opt/conda/lib/python3.7/site-packages (from ImageHash==4.1.0->-r requirements.txt (line 10)) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib==3.2.1->-r requirements.txt (line 11)) (0.11.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib==3.2.1->-r requirements.txt (line 11)) (3.0.7)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib==3.2.1->-r requirements.txt (line 11)) (1.4.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit_learn==0.23.2->-r requirements.txt (line 13)) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit_learn==0.23.2->-r requirements.txt (line 13)) (3.1.0)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from kiwisolver>=1.0.1->matplotlib==3.2.1->-r requirements.txt (line 11)) (4.1.1)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests>=2.20.0->paddlepaddle-gpu==1.8.3.post97->-r requirements.txt (line 8)) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests>=2.20.0->paddlepaddle-gpu==1.8.3.post97->-r requirements.txt (line 8)) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests>=2.20.0->paddlepaddle-gpu==1.8.3.post97->-r requirements.txt (line 8)) (2021.10.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests>=2.20.0->paddlepaddle-gpu==1.8.3.post97->-r requirements.txt (line 8)) (1.25.11)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from prettytable->paddlepaddle-gpu==1.8.3.post97->-r requirements.txt (line 8)) (4.11.3)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.7/site-packages (from prettytable->paddlepaddle-gpu==1.8.3.post97->-r requirements.txt (line 8)) (0.2.5)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->prettytable->paddlepaddle-gpu==1.8.3.post97->-r requirements.txt (line 8)) (3.7.0)\n",
      "Building wheels for collected packages: nltk, lmdb\n",
      "  Building wheel for nltk (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for nltk: filename=nltk-3.2.4-py3-none-any.whl size=1367724 sha256=31723a4d37faf1c21847dc411cbb2cb444ffee9e8a95134b16c39b770fd9ad16\n",
      "  Stored in directory: /home/jupyter/.cache/pip/wheels/90/5e/9e/4cb46185f2a16c60e6fc524372ba7fef89ce3347734c8798b6\n",
      "  Building wheel for lmdb (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for lmdb: filename=lmdb-0.97-cp37-cp37m-linux_x86_64.whl size=290659 sha256=1174a98f6dd1eb0867049e0e64872d56cde996825b32724bae5151ec7053e267\n",
      "  Stored in directory: /home/jupyter/.cache/pip/wheels/fc/9c/16/01d282ed6747f9eed531b21539e1e5e6be4adf093e2e2db7a6\n",
      "Successfully built nltk lmdb\n",
      "Installing collected packages: six, rarfile, pathlib, lmdb, funcsigs, scipy, opencv-python, nltk, json_lines, graphviz, astor, pandas, objgraph, paddlepaddle-gpu\n",
      "  Attempting uninstall: six\n",
      "    Found existing installation: six 1.14.0\n",
      "    Uninstalling six-1.14.0:\n",
      "      Successfully uninstalled six-1.14.0\n",
      "  Attempting uninstall: lmdb\n",
      "    Found existing installation: lmdb 1.0.0\n",
      "    Uninstalling lmdb-1.0.0:\n",
      "      Successfully uninstalled lmdb-1.0.0\n",
      "  Attempting uninstall: scipy\n",
      "    Found existing installation: scipy 1.4.1\n",
      "    Uninstalling scipy-1.4.1:\n",
      "      Successfully uninstalled scipy-1.4.1\n",
      "  Attempting uninstall: opencv-python\n",
      "    Found existing installation: opencv-python 4.5.5.64\n",
      "    Uninstalling opencv-python-4.5.5.64:\n",
      "      Successfully uninstalled opencv-python-4.5.5.64\n",
      "  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 1.1.3\n",
      "    Uninstalling pandas-1.1.3:\n",
      "      Successfully uninstalled pandas-1.1.3\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "wandb 0.10.8 requires six>=1.13.0, but you have six 1.11.0 which is incompatible.\n",
      "tensorflow 2.3.1 requires six>=1.12.0, but you have six 1.11.0 which is incompatible.\n",
      "statsmodels 0.13.2 requires packaging>=21.3, but you have packaging 20.1 which is incompatible.\n",
      "statsmodels 0.13.2 requires scipy>=1.3, but you have scipy 1.2.1 which is incompatible.\n",
      "phik 0.12.0 requires scipy>=1.5.2, but you have scipy 1.2.1 which is incompatible.\n",
      "pandas-profiling 3.0.0 requires pydantic>=1.8.1, but you have pydantic 1.7.2 which is incompatible.\n",
      "pandas-profiling 3.0.0 requires requests>=2.24.0, but you have requests 2.23.0 which is incompatible.\n",
      "pandas-profiling 3.0.0 requires scipy>=1.4.1, but you have scipy 1.2.1 which is incompatible.\n",
      "pandas-profiling 3.0.0 requires tangled-up-in-unicode==0.1.0, but you have tangled-up-in-unicode 0.2.0 which is incompatible.\n",
      "pandas-profiling 3.0.0 requires tqdm>=4.48.2, but you have tqdm 4.45.0 which is incompatible.\n",
      "kubernetes 23.3.0 requires pyyaml>=5.4.1, but you have pyyaml 5.3.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed astor-0.8.1 funcsigs-1.0.2 graphviz-0.20 json_lines-0.5.0 lmdb-0.97 nltk-3.2.4 objgraph-3.5.0 opencv-python-3.4.2.17 paddlepaddle-gpu-1.8.3.post97 pandas-1.0.5 pathlib-1.0.1 rarfile-4.0 scipy-1.2.1 six-1.11.0\n"
     ]
    }
   ],
   "source": [
    "#install requirements for ernie-vil\n",
    "!cd vilio/ernie-vil; pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9eb94b7a-9abd-4301-8c52-d481d1ee7482",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-05-05 20:35:17--  https://ernie-github.cdn.bcebos.com/model-ernie-vil-base-en.1.tar.gz\n",
      "Resolving ernie-github.cdn.bcebos.com (ernie-github.cdn.bcebos.com)... 183.136.216.35, 183.56.138.35, 183.134.235.35, ...\n",
      "Connecting to ernie-github.cdn.bcebos.com (ernie-github.cdn.bcebos.com)|183.136.216.35|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 886162849 (845M) [application/x-gzip]\n",
      "Saving to: ‘model-ernie-vil-base-en.1.tar.gz’\n",
      "\n",
      "model-ernie-vil-bas   0%[                    ]   4.00M  3.25MB/s    in 1.2s    \n",
      "\n",
      "2022-05-05 20:35:20 (3.25 MB/s) - Connection closed at byte 4194304. Retrying.\n",
      "\n",
      "--2022-05-05 20:35:21--  (try: 2)  https://ernie-github.cdn.bcebos.com/model-ernie-vil-base-en.1.tar.gz\n",
      "Connecting to ernie-github.cdn.bcebos.com (ernie-github.cdn.bcebos.com)|183.136.216.35|:443... connected.\n",
      "HTTP request sent, awaiting response... 206 Partial Content\n",
      "Length: 886162849 (845M), 881968545 (841M) remaining [application/x-gzip]\n",
      "Saving to: ‘model-ernie-vil-base-en.1.tar.gz’\n",
      "\n",
      "model-ernie-vil-bas 100%[===================>] 845.11M  16.7MB/s    in 53s     \n",
      "\n",
      "2022-05-05 20:36:15 (15.9 MB/s) - ‘model-ernie-vil-base-en.1.tar.gz’ saved [886162849/886162849]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://ernie-github.cdn.bcebos.com/model-ernie-vil-base-en.1.tar.gz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9660b2b-57e0-4873-8db2-ec5631ae69e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!tar -xf model-ernie-vil-base-en.1.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d52c3a38-a5ca-42c7-9db2-ae465e7bc64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mv model-ernie-vil-base-en/ ./vilio/ernie-vil/data/erniesmall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0ab328e0-7a9a-4461-9c13-dbfeb8b54ce9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config '/home/jupyter/vilio/py-bottom-up-attention/configs/VG-Detection/faster_rcnn_R_101_C4_attr_caffemaxpool.yaml' has no VERSION. Assuming it to be compatible with latest v2.\n",
      "Modifications for VG in ResNet Backbone (modeling/backbone/resnet.py):\n",
      "\tUsing pad 0 in stem max_pool instead of pad 1.\n",
      "\n",
      "Modifications for VG in RPN (modeling/proposal_generator/rpn.py):\n",
      "\tUse hidden dim 512 instead fo the same dim as Res4 (1024).\n",
      "\n",
      "Modifications for VG in RoI heads (modeling/roi_heads/roi_heads.py):\n",
      "\t1. Change the stride of conv1 and shortcut in Res5.Block1 from 2 to 1.\n",
      "\t2. Modifying all conv2 with (padding: 1 --> 2) and (dilation: 1 --> 2).\n",
      "\tFor more details, please check 'https://github.com/peteanderson80/bottom-up-attention/blob/master/models/vg/ResNet-101/faster_rcnn_end2end_final/test.prototxt'.\n",
      "\n",
      "Modifications for VG in RoI heads (modeling/roi_heads/fast_rcnn.py))\n",
      "\tEmbedding: 1601 --> 256\tLinear: 2304 --> 512\tLinear: 512 --> 401\n",
      "\n",
      "100%|█████████████████████████████████████| 10001/10001 [59:01<00:00,  2.82it/s]\n"
     ]
    }
   ],
   "source": [
    "!cd vilio/py-bottom-up-attention/; python detectron2_mscoco_proposal_maxnms.py --batchsize 4 --split img --weight vgattr \\\n",
    "--minboxes 10 --maxboxes 100\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9035c9d2-5547-483c-824c-c381bd35aad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mv vilio/py-bottom-up-attention/data/hm_vgattr10100.tsv ./vilio/ernie-vil/data/hm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f190d71-fdc8-411e-9084-6a4510667865",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!cd vilio/ernie-vil; bash bash/training/ES/hm_ES36.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36903721-3ce5-4668-b2a1-2db8ad886b7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Included in Simple Average:  dev_seenES36.csv\n",
      "Included in Simple Average:  test_seenES36.csv\n",
      "Included in Simple Average:  test_unseenES36.csv\n"
     ]
    }
   ],
   "source": [
    "!cd vilio/ernie-vil; bash bash/training/ES/hm_ESSA.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57d881ee-03ea-41d5-ad23-10c20c0ff9ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-06 16:01:03.715935: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
      "comet_ml is installed but `COMET_API_KEY` is not set.\n",
      "Load 7459 data from split(s) train.\n",
      "Start to load Faster-RCNN detected objects from data/HM_img.tsv\n",
      "Loaded 7459 images in file data/HM_img.tsv in 45 seconds.\n",
      "Use 7459 data in torch dataset\n",
      "\n",
      "Load 500 data from split(s) dev_seen.\n",
      "Start to load Faster-RCNN detected objects from data/HM_img.tsv\n",
      "Loaded 500 images in file data/HM_img.tsv in 34 seconds.\n",
      "Use 500 data in torch dataset\n",
      "\n",
      "Some weights of BertU were not initialized from the model checkpoint at bert-large-cased and are newly initialized: ['bert.img_embeddings.img_linear.weight', 'bert.img_embeddings.img_linear.bias', 'bert.img_embeddings.img_layer_norm.weight', 'bert.img_embeddings.img_layer_norm.bias', 'bert.img_embeddings.pos_layer_norm.weight', 'bert.img_embeddings.pos_layer_norm.bias', 'bert.img_embeddings.pos_linear.weight', 'bert.img_embeddings.pos_linear.bias', 'bert.img_embeddings.LayerNorm.weight', 'bert.img_embeddings.LayerNorm.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "UNEXPECTED:  []\n",
      "MISSING:  ['bert.img_embeddings.img_linear.weight', 'bert.img_embeddings.img_linear.bias', 'bert.img_embeddings.img_layer_norm.weight', 'bert.img_embeddings.img_layer_norm.bias', 'bert.img_embeddings.pos_layer_norm.weight', 'bert.img_embeddings.pos_layer_norm.bias', 'bert.img_embeddings.pos_linear.weight', 'bert.img_embeddings.pos_linear.bias', 'bert.img_embeddings.LayerNorm.weight', 'bert.img_embeddings.LayerNorm.bias']\n",
      "ERRORS:  []\n",
      "REINITING:  Linear(in_features=1024, out_features=2048, bias=True)\n",
      "REINITING:  GeLU()\n",
      "REINITING:  LayerNorm((2048,), eps=1e-12, elementwise_affine=True)\n",
      "REINITING:  Linear(in_features=2048, out_features=2, bias=True)\n",
      "REINITING:  Sequential(\n",
      "  (0): Linear(in_features=1024, out_features=2048, bias=True)\n",
      "  (1): GeLU()\n",
      "  (2): LayerNorm((2048,), eps=1e-12, elementwise_affine=True)\n",
      "  (3): Linear(in_features=2048, out_features=2, bias=True)\n",
      ")\n",
      "Load pre-trained model from ./data/uniter-large.pt\n",
      "\n",
      "Weights in loaded but not in model:\n",
      "cls.predictions.bias\n",
      "cls.predictions.decoder.weight\n",
      "cls.predictions.transform.LayerNorm.bias\n",
      "cls.predictions.transform.LayerNorm.weight\n",
      "cls.predictions.transform.dense.bias\n",
      "cls.predictions.transform.dense.weight\n",
      "feat_regress.bias\n",
      "feat_regress.net.0.bias\n",
      "feat_regress.net.0.weight\n",
      "feat_regress.net.2.bias\n",
      "feat_regress.net.2.weight\n",
      "feat_regress.weight\n",
      "img_embeddings.mask_embedding.weight\n",
      "itm_output.bias\n",
      "itm_output.weight\n",
      "region_classifier.net.0.bias\n",
      "region_classifier.net.0.weight\n",
      "region_classifier.net.2.bias\n",
      "region_classifier.net.2.weight\n",
      "region_classifier.net.3.bias\n",
      "region_classifier.net.3.weight\n",
      "\n",
      "Weights in model but not in loaded:\n",
      "embeddings.position_ids\n",
      "\n",
      "Total Iters: 4665\n",
      "/opt/conda/lib/python3.7/site-packages/torchcontrib/optim/swa.py:130: UserWarning: Casting swa_start, swa_freq to int\n",
      "  warnings.warn(\"Casting swa_start, swa_freq to int\")\n",
      "Splits in Train data: ['train']\n",
      "Splits in Valid data: ['dev_seen']\n",
      "Batches: 933\n",
      "tensor([-0.8743, -0.5398], device='cuda:0')\n",
      "\n",
      "Epoch(U) 0(250): Train AC 59.65 RA 52.0085 LOSS 1373.9120\n",
      "\n",
      "Epoch(U) 0(250): DEV AC 53.20 RA 62.2784 \n",
      "Epoch(U) 0(250): BEST AC 53.20 RA 62.2784 \n",
      "\n",
      "Epoch(U) 0(500): Train AC 60.42 RA 56.5861 LOSS 1327.6975\n",
      "\n",
      "Epoch(U) 0(500): DEV AC 53.20 RA 66.2160 \n",
      "Epoch(U) 0(500): BEST AC 53.20 RA 66.2160 \n",
      "\n",
      "Epoch(U) 0(750): Train AC 62.02 RA 61.5518 LOSS 1265.4148\n",
      "\n",
      "Epoch(U) 0(750): DEV AC 60.40 RA 70.4720 \n",
      "Epoch(U) 0(750): BEST AC 60.40 RA 70.4720 \n",
      "tensor([-0.4857, -0.9552], device='cuda:0')\n",
      "\n",
      "Epoch(U) 1(1000): Train AC 79.66 RA 85.9173 LOSS 1049.4866\n",
      "\n",
      "Epoch(U) 1(1000): DEV AC 64.60 RA 75.1520 \n",
      "Epoch(U) 1(1000): BEST AC 64.60 RA 75.1520 \n",
      "\n",
      "Epoch(U) 1(1250): Train AC 80.01 RA 86.9145 LOSS 902.6017\n",
      "\n",
      "Epoch(U) 1(1250): DEV AC 66.80 RA 75.2240 \n",
      "Epoch(U) 1(1250): BEST AC 66.80 RA 75.2240 \n",
      "\n",
      "Epoch(U) 1(1500): Train AC 80.16 RA 86.6746 LOSS 909.0008\n",
      "\n",
      "Epoch(U) 1(1500): DEV AC 62.80 RA 76.0944 \n",
      "Epoch(U) 1(1500): BEST AC 62.80 RA 76.0944 \n",
      "\n",
      "Epoch(U) 1(1750): Train AC 80.17 RA 86.6559 LOSS 894.2397\n",
      "\n",
      "Epoch(U) 1(1750): DEV AC 68.40 RA 77.2336 \n",
      "Epoch(U) 1(1750): BEST AC 68.40 RA 77.2336 \n",
      "tensor([-0.0571, -2.8910], device='cuda:0')\n",
      "\n",
      "Epoch(U) 2(2000): Train AC 91.79 RA 95.2550 LOSS 740.9696\n",
      "\n",
      "Epoch(U) 2(2000): DEV AC 68.60 RA 76.5008 \n",
      "Epoch(U) 2(2000): BEST AC 68.40 RA 77.2336 \n",
      "\n",
      "Epoch(U) 2(2250): Train AC 91.83 RA 95.6907 LOSS 705.5853\n",
      "\n",
      "Epoch(U) 2(2250): DEV AC 67.60 RA 77.8464 \n",
      "Epoch(U) 2(2250): BEST AC 67.60 RA 77.8464 \n",
      "\n",
      "Epoch(U) 2(2500): Train AC 91.42 RA 95.3029 LOSS 771.0157\n",
      "\n",
      "Epoch(U) 2(2500): DEV AC 66.00 RA 76.2816 \n",
      "Epoch(U) 2(2500): BEST AC 67.60 RA 77.8464 \n",
      "\n",
      "Epoch(U) 2(2750): Train AC 91.16 RA 95.6684 LOSS 642.4614\n",
      "\n",
      "Epoch(U) 2(2750): DEV AC 65.20 RA 77.7776 \n",
      "Epoch(U) 2(2750): BEST AC 67.60 RA 77.8464 \n",
      "tensor([-1.4691e-03, -6.5238e+00], device='cuda:0')\n",
      "\n",
      "Epoch(U) 3(3000): Train AC 94.90 RA 97.3856 LOSS 529.7842\n",
      "\n",
      "Epoch(U) 3(3000): DEV AC 69.20 RA 77.8008 \n",
      "Epoch(U) 3(3000): BEST AC 67.60 RA 77.8464 \n",
      "\n",
      "Epoch(U) 3(3250): Train AC 95.29 RA 98.0319 LOSS 430.0379\n",
      "\n",
      "Epoch(U) 3(3250): DEV AC 67.60 RA 76.5312 \n",
      "Epoch(U) 3(3250): BEST AC 67.60 RA 77.8464 \n",
      "\n",
      "Epoch(U) 3(3500): Train AC 95.49 RA 98.0737 LOSS 450.3947\n",
      "\n",
      "Epoch(U) 3(3500): DEV AC 66.80 RA 75.0912 \n",
      "Epoch(U) 3(3500): BEST AC 67.60 RA 77.8464 \n",
      "tensor([-6.6944e+00, -1.2386e-03], device='cuda:0')\n",
      "\n",
      "Epoch(U) 4(3750): Train AC 95.83 RA 98.4876 LOSS 507.1811\n",
      "\n",
      "Epoch(U) 4(3750): DEV AC 68.20 RA 74.3744 \n",
      "Epoch(U) 4(3750): BEST AC 67.60 RA 77.8464 \n",
      "\n",
      "Epoch(U) 4(4000): Train AC 95.57 RA 98.1159 LOSS 471.2435\n",
      "\n",
      "Epoch(U) 4(4000): DEV AC 67.00 RA 73.9296 \n",
      "Epoch(U) 4(4000): BEST AC 67.60 RA 77.8464 \n",
      "\n",
      "Epoch(U) 4(4250): Train AC 95.97 RA 98.0218 LOSS 415.6941\n",
      "\n",
      "Epoch(U) 4(4250): DEV AC 69.40 RA 76.1984 \n",
      "Epoch(U) 4(4250): BEST AC 67.60 RA 77.8464 \n",
      "\n",
      "Epoch(U) 4(4500): Train AC 95.52 RA 97.7161 LOSS 608.3432\n",
      "\n",
      "Epoch(U) 4(4500): DEV AC 69.00 RA 74.5696 \n",
      "Epoch(U) 4(4500): BEST AC 67.60 RA 77.8464 \n",
      "Load model from ./data/LASTtrain.pth\n",
      "Load 500 data from split(s) dev_seen.\n",
      "Start to load Faster-RCNN detected objects from data/HM_img.tsv\n",
      "Loaded 500 images in file data/HM_img.tsv in 34 seconds.\n",
      "Use 500 data in torch dataset\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 500 entries, 0 to 499\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   id      500 non-null    int64  \n",
      " 1   proba   500 non-null    float64\n",
      " 2   label   500 non-null    int64  \n",
      "dtypes: float64(1), int64(2)\n",
      "memory usage: 11.8 KB\n",
      "None\n",
      "(0.694, 0.7582239999999999)\n",
      "2022-05-06 16:44:27.168249: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
      "comet_ml is installed but `COMET_API_KEY` is not set.\n",
      "Load 8959 data from split(s) traindev.\n",
      "Start to load Faster-RCNN detected objects from data/HM_img.tsv\n",
      "Loaded 8959 images in file data/HM_img.tsv in 48 seconds.\n",
      "Use 8959 data in torch dataset\n",
      "\n",
      "Load 500 data from split(s) dev_seen.\n",
      "Start to load Faster-RCNN detected objects from data/HM_img.tsv\n",
      "Loaded 500 images in file data/HM_img.tsv in 34 seconds.\n",
      "Use 500 data in torch dataset\n",
      "\n",
      "Some weights of BertU were not initialized from the model checkpoint at bert-large-cased and are newly initialized: ['bert.img_embeddings.img_linear.weight', 'bert.img_embeddings.img_linear.bias', 'bert.img_embeddings.img_layer_norm.weight', 'bert.img_embeddings.img_layer_norm.bias', 'bert.img_embeddings.pos_layer_norm.weight', 'bert.img_embeddings.pos_layer_norm.bias', 'bert.img_embeddings.pos_linear.weight', 'bert.img_embeddings.pos_linear.bias', 'bert.img_embeddings.LayerNorm.weight', 'bert.img_embeddings.LayerNorm.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "UNEXPECTED:  []\n",
      "MISSING:  ['bert.img_embeddings.img_linear.weight', 'bert.img_embeddings.img_linear.bias', 'bert.img_embeddings.img_layer_norm.weight', 'bert.img_embeddings.img_layer_norm.bias', 'bert.img_embeddings.pos_layer_norm.weight', 'bert.img_embeddings.pos_layer_norm.bias', 'bert.img_embeddings.pos_linear.weight', 'bert.img_embeddings.pos_linear.bias', 'bert.img_embeddings.LayerNorm.weight', 'bert.img_embeddings.LayerNorm.bias']\n",
      "ERRORS:  []\n",
      "REINITING:  Linear(in_features=1024, out_features=2048, bias=True)\n",
      "REINITING:  GeLU()\n",
      "REINITING:  LayerNorm((2048,), eps=1e-12, elementwise_affine=True)\n",
      "REINITING:  Linear(in_features=2048, out_features=2, bias=True)\n",
      "REINITING:  Sequential(\n",
      "  (0): Linear(in_features=1024, out_features=2048, bias=True)\n",
      "  (1): GeLU()\n",
      "  (2): LayerNorm((2048,), eps=1e-12, elementwise_affine=True)\n",
      "  (3): Linear(in_features=2048, out_features=2, bias=True)\n",
      ")\n",
      "Load pre-trained model from ./data/uniter-large.pt\n",
      "\n",
      "Weights in loaded but not in model:\n",
      "cls.predictions.bias\n",
      "cls.predictions.decoder.weight\n",
      "cls.predictions.transform.LayerNorm.bias\n",
      "cls.predictions.transform.LayerNorm.weight\n",
      "cls.predictions.transform.dense.bias\n",
      "cls.predictions.transform.dense.weight\n",
      "feat_regress.bias\n",
      "feat_regress.net.0.bias\n",
      "feat_regress.net.0.weight\n",
      "feat_regress.net.2.bias\n",
      "feat_regress.net.2.weight\n",
      "feat_regress.weight\n",
      "img_embeddings.mask_embedding.weight\n",
      "itm_output.bias\n",
      "itm_output.weight\n",
      "region_classifier.net.0.bias\n",
      "region_classifier.net.0.weight\n",
      "region_classifier.net.2.bias\n",
      "region_classifier.net.2.weight\n",
      "region_classifier.net.3.bias\n",
      "region_classifier.net.3.weight\n",
      "\n",
      "Weights in model but not in loaded:\n",
      "embeddings.position_ids\n",
      "\n",
      "Total Iters: 5600\n",
      "/opt/conda/lib/python3.7/site-packages/torchcontrib/optim/swa.py:130: UserWarning: Casting swa_start, swa_freq to int\n",
      "  warnings.warn(\"Casting swa_start, swa_freq to int\")\n",
      "Splits in Train data: ['traindev']\n",
      "Splits in Valid data: ['dev_seen']\n",
      "Batches: 1120\n",
      "tensor([-0.9888, -0.4652], device='cuda:0')\n",
      "\n",
      "Epoch(U) 0(250): Train AC 60.95 RA 50.1899 LOSS 1385.3800\n",
      "\n",
      "Epoch(U) 0(250): DEV AC 50.00 RA 49.2864 \n",
      "Epoch(U) 0(250): BEST AC 50.00 RA 49.2864 \n",
      "\n",
      "Epoch(U) 0(500): Train AC 62.65 RA 56.9840 LOSS 1294.6746\n",
      "\n",
      "Epoch(U) 0(500): DEV AC 54.20 RA 70.5824 \n",
      "Epoch(U) 0(500): BEST AC 54.20 RA 70.5824 \n",
      "\n",
      "Epoch(U) 0(750): Train AC 64.75 RA 63.0025 LOSS 1210.2106\n",
      "\n",
      "Epoch(U) 0(750): DEV AC 67.40 RA 76.8768 \n",
      "Epoch(U) 0(750): BEST AC 67.40 RA 76.8768 \n",
      "\n",
      "Epoch(U) 0(1000): Train AC 66.62 RA 67.3557 LOSS 1122.8698\n",
      "\n",
      "Epoch(U) 0(1000): DEV AC 70.60 RA 81.7968 \n",
      "Epoch(U) 0(1000): BEST AC 70.60 RA 81.7968 \n",
      "tensor([-1.2634, -0.3322], device='cuda:0')\n",
      "\n",
      "Epoch(U) 1(1250): Train AC 81.73 RA 86.4007 LOSS 960.2116\n",
      "\n",
      "Epoch(U) 1(1250): DEV AC 67.20 RA 85.5344 \n",
      "Epoch(U) 1(1250): BEST AC 67.20 RA 85.5344 \n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"hm.py\", line 391, in <module>\n",
      "    main()\n",
      "  File \"hm.py\", line 358, in main\n",
      "    hm.train(hm.train_tuple, hm.valid_tuple)\n",
      "  File \"hm.py\", line 219, in train\n",
      "    self.optim.step()\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torchcontrib/optim/swa.py\", line 205, in step\n",
      "    loss = self.optimizer.step(closure)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py\", line 66, in wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "  File \"/home/jupyter/vilio/src/vilio/transformers/optimization.py\", line 300, in step\n",
      "    p.data.addcdiv_(exp_avg, denom, value=-step_size)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "#train uniter \n",
    "!cd vilio; bash bash/training/U/hm_U36.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fbc481e-60b7-422b-9668-5cc51f97bd04",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "pytorch-gpu.1-11.m91",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-11:m91"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
