{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2fdfe72c-52c9-4b34-b7dd-bed4ea581e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import collections\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import joblib\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd0cdba8-c0c4-40ad-a8ad-c4a140f2a670",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(truth_json, predicted_path):\n",
    "    \n",
    "    predicted = pd.read_csv(predicted_path)\n",
    "    correct = 0\n",
    "    truth_dict = collections.Counter()\n",
    "    \n",
    "    with open(truth_json, 'r') as json_file:\n",
    "        json_list = list(json_file)\n",
    "\n",
    "    for i, json_str in enumerate(json_list):\n",
    "        result = json.loads(json_str)\n",
    "        truth_dict[result['label']] += 1\n",
    "        if result['label'] == predicted['label'][i]:\n",
    "            correct += 1\n",
    "    print(correct, len(json_list))\n",
    "    print(truth_dict.items())\n",
    "\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfbee94a-a7b8-429c-b841-89897500d3b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62b8abdf-83c2-492f-829e-71cfe209e4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def json_to_csv(truth_json):\n",
    "    dict = collections.defaultdict(list)\n",
    "    with open(truth_json, 'r') as json_file:\n",
    "        json_list = list(json_file)\n",
    "    for i, json_str in enumerate(json_list):\n",
    "        result = json.loads(json_str)\n",
    "        dict['label'].append(result['label'])\n",
    "        dict['id'].append(result['id'])\n",
    "        dict['text'].append(result['text'])\n",
    "    df = pd.DataFrame(data=dict)\n",
    "    return df\n",
    "\n",
    "def log_to_proba(file, res_file):\n",
    "    df = pd.read_csv(file)\n",
    "    df['proba'] = df['proba'].apply(lambda x: np.exp(x))\n",
    "    \n",
    "    df.to_csv(res_file, index=False)\n",
    "    return df\n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a294e81-3c18-4f5b-8916-df07b519a9b6",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './uniter-oscar/vilio/data/O36/O36_test_unseen_SA.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_150005/2498977630.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mlog_to_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./uniter-oscar/vilio/Ensemble_files/U36_test_unseen.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"./uniter-oscar/vilio/Ensemble_files/U36_test_unseen_converted.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlog_to_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./uniter-oscar/vilio/data/O36/O36_test_unseen_SA.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"./uniter-oscar/vilio/Ensemble_files/O36_test_unseen_converted.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_150005/2044499800.py\u001b[0m in \u001b[0;36mlog_to_proba\u001b[0;34m(file, res_file)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mlog_to_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'proba'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'proba'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    227\u001b[0m             \u001b[0mmemory_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m             \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"encoding_errors\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"strict\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m         )\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    705\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 707\u001b[0;31m                 \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    708\u001b[0m             )\n\u001b[1;32m    709\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './uniter-oscar/vilio/data/O36/O36_test_unseen_SA.csv'"
     ]
    }
   ],
   "source": [
    "log_to_proba(\"./uniter-oscar/vilio/Ensemble_files/U36_test_unseen.csv\", \"./uniter-oscar/vilio/Ensemble_files/U36_test_unseen_converted.csv\")\n",
    "log_to_proba(\"./uniter-oscar/vilio/data/O36/O36_test_unseen_SA.csv\", \"./uniter-oscar/vilio/Ensemble_files/O36_test_unseen_converted.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c7318bb1-0a8a-41ae-aec8-c43a3ce15a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ground_truth = json_to_csv('./vilio/data/test_unseen.jsonl')\n",
    "test_ground_truth.to_csv('./vilio/Ensemble_files/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "a8823014-0958-4746-a525-cedf9b3e91a7",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/jupyter/.cache/torch/mmf/data/datasets/hateful_memes/defaults/annotations/test.jsonl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4589/2694025579.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/home/jupyter/.cache/torch/mmf/data/datasets/hateful_memes/defaults/annotations/test.jsonl\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"./vilbert/output/test.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_4589/761950188.py\u001b[0m in \u001b[0;36maccuracy\u001b[0;34m(truth_json, predicted_path)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mtruth_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCounter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtruth_json\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mjson_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mjson_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/jupyter/.cache/torch/mmf/data/datasets/hateful_memes/defaults/annotations/test.jsonl'"
     ]
    }
   ],
   "source": [
    "accuracy(\"/home/jupyter/.cache/torch/mmf/data/datasets/hateful_memes/defaults/annotations/test.jsonl\", \"./vilbert/output/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "48f41c67-495b-493d-9979-81643f5d7267",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Ensemble:\n",
    "    def __init__(self, ground_truth, uniter, oscar, visual_bert, vilbert, ground_truth_train, uniter_train, visual_bert_train, vilbert_train):\n",
    "        self.ground_truth = self.jsonl_to_df(ground_truth)\n",
    "        self.uniter = pd.read_csv(uniter)\n",
    "        self.oscar = pd.read_csv(oscar)\n",
    "        self.visual_bert = self.mmf_read_csv(visual_bert)\n",
    "        self.vilbert = self.mmf_read_csv(vilbert)\n",
    "        \n",
    "        self.ground_truth_train = self.jsonl_to_df(ground_truth_train)\n",
    "        self.uniter_train = self.log_to_proba(uniter_train)\n",
    "        self.visual_bert_train = self.mmf_read_csv(visual_bert_train)\n",
    "        self.vilbert_train = self.mmf_read_csv(vilbert_train)\n",
    "        \n",
    "        self.combined = self.combine()\n",
    "        \n",
    "    def jsonl_to_df(self, jsonl_path):\n",
    "        dict = collections.defaultdict(list)\n",
    "        with open(jsonl_path, 'r') as json_file:\n",
    "            json_list = list(json_file)\n",
    "        for i, json_str in enumerate(json_list):\n",
    "            result = json.loads(json_str)\n",
    "            dict['label'].append(result['label'])\n",
    "            dict['id'].append(result['id'])\n",
    "            dict['text'].append(result['text'])\n",
    "        df = pd.DataFrame(data=dict)\n",
    "        return df\n",
    "        \n",
    "    def log_to_proba(self, file):\n",
    "        df = pd.read_csv(file)\n",
    "        df['proba'] = df['proba'].apply(lambda x: np.exp(x))\n",
    "        return df\n",
    "        \n",
    "    def mmf_read_csv(self, path):\n",
    "        \n",
    "        df = pd.read_csv(path)\n",
    "        df['proba'] = df['scores'].apply(lambda x: float(x[1:-1].split(\", \")[1]))\n",
    "        df = df.drop(columns=['scores'])\n",
    "        df['label'] = df['proba'].apply(lambda x: 1 if x >= 0.5 else 0)\n",
    "        return df\n",
    "        \n",
    "    \n",
    "    def compare(self, predict, array=False):\n",
    "        correct = 0\n",
    "        all = len(predict)\n",
    "        for i in range(all):\n",
    "            if predict['result'][i] == self.ground_truth['label'][i]:\n",
    "                correct += 1\n",
    "        #print(correct, '/', all, \"Accuracy:\", correct/all)\n",
    "        return correct/all\n",
    "    \n",
    "    def combine(self):\n",
    "        combine_a = pd.merge(self.uniter, self.oscar, on='id', suffixes=('_u', '_x'), left_index=False, right_index=False)\n",
    "        combine_b = pd.merge(self.visual_bert, self.vilbert, on='id', suffixes=('_y', '_z'), left_index=False, right_index=False)\n",
    "        combined = pd.merge(combine_a, combine_b, how='left', on='id')\n",
    "        return combined\n",
    "        \n",
    "    \n",
    "    def simple_average(self):\n",
    "        cols = ['proba_u','proba_x','proba_y','proba_z']\n",
    "        \n",
    "        combined = self.combined\n",
    "        \n",
    "        combined['avg'] = combined[cols].mean(axis=1)\n",
    "        combined['result'] = combined['avg'].apply(lambda x: 1 if x >= 0.5 else 0)\n",
    "        acc = self.compare(combined)\n",
    "        print(\"Simple Average Accuracy:\", acc)\n",
    "        return combined\n",
    "    \n",
    "    def single_model_acc(self):\n",
    "        self.uniter['result'] = self.uniter['proba'].apply(lambda x: 1 if x >= 0.5 else 0)\n",
    "        acc = self.compare(self.uniter)\n",
    "        print(\"Uniter Accuracy :\", acc)\n",
    "        \n",
    "        self.oscar['result'] = self.oscar['proba'].apply(lambda x: 1 if x >= 0.5 else 0)\n",
    "        acc = self.compare(self.oscar)\n",
    "        print(\"Oscar Accuracy :\", acc)\n",
    "        \n",
    "        self.visual_bert['result'] = self.visual_bert['proba'].apply(lambda x: 1 if x >= 0.5 else 0)\n",
    "        acc = self.compare(self.visual_bert)\n",
    "        print(\"Visual BERT Accuracy :\", acc)\n",
    "        \n",
    "        self.vilbert['result'] = self.vilbert['proba'].apply(lambda x: 1 if x >= 0.5 else 0)\n",
    "        acc = self.compare(self.vilbert)\n",
    "        print(\"VilBERT Accuracy :\", acc)\n",
    "        \n",
    "    \n",
    "    def weighted_average(self):\n",
    "        combined = self.combined\n",
    "        max_acc = 0\n",
    "        best_config = [0, 0, 0, 0]\n",
    "        \n",
    "        for i in range(1, 10):\n",
    "            for j in range(1, 10):\n",
    "                for k in range(1, 10):\n",
    "                    for l in range(1, 10):\n",
    "                        combined['avg'] = (combined['proba_u']*i + combined['proba_x']*j + combined['proba_y']*k + combined['proba_z']*l)/(i+j+k+l)\n",
    "                        combined['result'] = combined['avg'].apply(lambda x: 1 if x >= 0.5 else 0)\n",
    "                        acc = self.compare(combined)\n",
    "                        if acc > max_acc:\n",
    "                            max_acc = acc\n",
    "                            best_config = [i, j, k, l]\n",
    "        \n",
    "        return max_acc, best_config\n",
    "        \n",
    "    \n",
    "    def random_forest_train(self):\n",
    "        \n",
    "        combine_a = pd.merge(self.uniter_train, self.visual_bert_train, on='id', suffixes=('_u', '_y'), left_index=False, right_index=False)\n",
    "        combined = pd.merge(combine_a, self.vilbert_train, on='id', left_index=False, right_index=False)\n",
    "        self.X_train = combined[['proba_u','proba_y','proba']].replace(np.nan, 0)\n",
    "        self.y_train = self.ground_truth_train['label']\n",
    "        \n",
    "        # X = train_data['proba'].to_numpy()\n",
    "        # X = [[i] for i in X]\n",
    "        # y = train_data['label'].to_numpy()\n",
    "\n",
    "        rf = RandomForestRegressor()\n",
    "        rf.fit(self.X_train, self.y_train)\n",
    "        joblib.dump(rf, \"./random_forest.joblib\")\n",
    "        print(\"completed\")\n",
    "    \n",
    "    def random_forest_predict(self, model):\n",
    "        \n",
    "        self.X_test = self.combined[['proba_u','proba_y','proba_z']].replace(np.nan, 0)\n",
    "        self.y_test = self.ground_truth['label'].replace(np.nan, 0)\n",
    "        \n",
    "        loaded_rf = joblib.load(model)\n",
    "        result = loaded_rf.predict(self.X_test)\n",
    "        result = np.where(result<0.5, 0, 1)\n",
    "        acc = np.mean(np.equal(result, self.y_test.to_numpy()))\n",
    "        print(\"Accuracy:\", acc)\n",
    "        \n",
    "        \n",
    "        # combined = self.simple_average()\n",
    "        # X = combined['avg'].to_numpy()\n",
    "        # X = X.reshape(-1, 1)\n",
    "        # result = loaded_rf.predict(X)\n",
    "        \n",
    "        # correct = 0\n",
    "        # all = len(result)\n",
    "        # for i in range(all):\n",
    "        #     if result[i] == self.ground_truth['label'][i]:\n",
    "        #         correct += 1\n",
    "        # print(correct, '/', all, \"Accuracy:\", correct/all)\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "cdf9f4b9-922e-40da-9c46-195762cc00f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble = Ensemble(\"./test.jsonl\",\n",
    "                    \"./uniter-oscar/vilio/Ensemble_files/U36_test_unseen_converted.csv\",\n",
    "                    \"./uniter-oscar/vilio/Ensemble_files/O36_test_unseen_converted.csv\", \n",
    "                    \"./vilbert/output/test.csv\",\n",
    "                    \"./visual_bert/output/test.csv\",\n",
    "                    \"./train.jsonl\",\n",
    "                    \"./uniter-oscar/vilio/Ensemble_files/U36_train.csv\",\n",
    "                    \"./vilbert/output/train.csv\",\n",
    "                    \"./visual_bert/output/train.csv\"\n",
    "                   )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "3741e23d-b64e-47fd-baca-c76218fed9e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uniter Accuracy : 0.65\n",
      "Oscar Accuracy : 0.647\n",
      "Visual BERT Accuracy : 0.749\n",
      "VilBERT Accuracy : 0.751\n"
     ]
    }
   ],
   "source": [
    "ensemble.single_model_acc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "d36d7461-2272-4a6a-a85a-f02cde04f7d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed\n"
     ]
    }
   ],
   "source": [
    "ensemble.random_forest_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "a4ad677d-d9b3-4639-adda-890d12975143",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/base.py:493: FutureWarning: The feature names should match those that were passed during fit. Starting version 1.2, an error will be raised.\n",
      "Feature names unseen at fit time:\n",
      "- proba_z\n",
      "Feature names seen at fit time, yet now missing:\n",
      "- proba\n",
      "\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "ensemble.random_forest_predict(\"./random_forest.joblib\",)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "0557437e-2fa1-4a6c-9555-2c024fa20485",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>proba_u</th>\n",
       "      <th>proba_y</th>\n",
       "      <th>proba</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000325</td>\n",
       "      <td>0.016702</td>\n",
       "      <td>0.003083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000332</td>\n",
       "      <td>0.002615</td>\n",
       "      <td>0.003664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000260</td>\n",
       "      <td>0.000546</td>\n",
       "      <td>0.003114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000475</td>\n",
       "      <td>0.000515</td>\n",
       "      <td>0.005600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000355</td>\n",
       "      <td>0.000345</td>\n",
       "      <td>0.002541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7495</th>\n",
       "      <td>0.999927</td>\n",
       "      <td>0.993523</td>\n",
       "      <td>0.996348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7496</th>\n",
       "      <td>0.999811</td>\n",
       "      <td>0.998505</td>\n",
       "      <td>0.995791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7497</th>\n",
       "      <td>0.999956</td>\n",
       "      <td>0.997529</td>\n",
       "      <td>0.994840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7498</th>\n",
       "      <td>0.999967</td>\n",
       "      <td>0.999054</td>\n",
       "      <td>0.995344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7499</th>\n",
       "      <td>0.999809</td>\n",
       "      <td>0.998882</td>\n",
       "      <td>0.994695</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7500 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       proba_u   proba_y     proba\n",
       "0     0.000325  0.016702  0.003083\n",
       "1     0.000332  0.002615  0.003664\n",
       "2     0.000260  0.000546  0.003114\n",
       "3     0.000475  0.000515  0.005600\n",
       "4     0.000355  0.000345  0.002541\n",
       "...        ...       ...       ...\n",
       "7495  0.999927  0.993523  0.996348\n",
       "7496  0.999811  0.998505  0.995791\n",
       "7497  0.999956  0.997529  0.994840\n",
       "7498  0.999967  0.999054  0.995344\n",
       "7499  0.999809  0.998882  0.994695\n",
       "\n",
       "[7500 rows x 3 columns]"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble.X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "f89cf02a-8e40-4999-b58f-27e9d0290863",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple Average Accuracy: 0.648\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>proba_u</th>\n",
       "      <th>label_u</th>\n",
       "      <th>proba_x</th>\n",
       "      <th>label_x</th>\n",
       "      <th>proba_y</th>\n",
       "      <th>label_y</th>\n",
       "      <th>proba_z</th>\n",
       "      <th>label_z</th>\n",
       "      <th>avg</th>\n",
       "      <th>result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>42953</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>0</td>\n",
       "      <td>0.026402</td>\n",
       "      <td>0</td>\n",
       "      <td>0.004799</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003127</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008599</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23058</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>0</td>\n",
       "      <td>0.002381</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000394</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002611</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001365</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13894</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0</td>\n",
       "      <td>0.003865</td>\n",
       "      <td>0</td>\n",
       "      <td>0.004470</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002874</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002814</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37408</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0</td>\n",
       "      <td>0.007473</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000793</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003317</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002909</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>82403</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0</td>\n",
       "      <td>0.238715</td>\n",
       "      <td>0</td>\n",
       "      <td>0.329488</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.772131</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.335096</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>23705</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>0</td>\n",
       "      <td>0.012218</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.006165</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>49806</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0</td>\n",
       "      <td>0.009403</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.004726</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>40813</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0</td>\n",
       "      <td>0.009714</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.004881</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>1468</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>0</td>\n",
       "      <td>0.125314</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.062681</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>10589</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>0</td>\n",
       "      <td>0.005415</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002740</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id   proba_u  label_u   proba_x  label_x   proba_y  label_y   proba_z  \\\n",
       "0    42953  0.000067        0  0.026402        0  0.004799      0.0  0.003127   \n",
       "1    23058  0.000073        0  0.002381        0  0.000394      0.0  0.002611   \n",
       "2    13894  0.000044        0  0.003865        0  0.004470      0.0  0.002874   \n",
       "3    37408  0.000052        0  0.007473        0  0.000793      0.0  0.003317   \n",
       "4    82403  0.000048        0  0.238715        0  0.329488      0.0  0.772131   \n",
       "..     ...       ...      ...       ...      ...       ...      ...       ...   \n",
       "995  23705  0.000113        0  0.012218        0       NaN      NaN       NaN   \n",
       "996  49806  0.000049        0  0.009403        0       NaN      NaN       NaN   \n",
       "997  40813  0.000048        0  0.009714        0       NaN      NaN       NaN   \n",
       "998   1468  0.000047        0  0.125314        0       NaN      NaN       NaN   \n",
       "999  10589  0.000065        0  0.005415        0       NaN      NaN       NaN   \n",
       "\n",
       "     label_z       avg  result  \n",
       "0        0.0  0.008599       0  \n",
       "1        0.0  0.001365       0  \n",
       "2        0.0  0.002814       0  \n",
       "3        0.0  0.002909       0  \n",
       "4        1.0  0.335096       0  \n",
       "..       ...       ...     ...  \n",
       "995      NaN  0.006165       0  \n",
       "996      NaN  0.004726       0  \n",
       "997      NaN  0.004881       0  \n",
       "998      NaN  0.062681       0  \n",
       "999      NaN  0.002740       0  \n",
       "\n",
       "[1000 rows x 11 columns]"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble.simple_average()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "295e260e-20ed-4a6a-b93a-06f48094b524",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def mmf_acc(df, dataset):\n",
    "    \n",
    "    dev_label = dict()\n",
    "\n",
    "    acc_count = 0\n",
    "    total_count = 0\n",
    "\n",
    "    with open(f'/home/jupyter/.cache/torch/mmf/data/datasets/hateful_memes/defaults/annotations/{dataset}.jsonl', 'r') as f:\n",
    "        for line in f:\n",
    "            total_count += 1\n",
    "\n",
    "            data = json.loads(line)\n",
    "            [imid, url, label, text] = data['id'], data['img'], data['label'], data['text']\n",
    "            dev_label[imid] = label\n",
    "\n",
    "            if df.loc[df['id'] == int(imid)]['label'].item() == int(label):\n",
    "                acc_count += 1\n",
    "\n",
    "    print(acc_count, total_count, acc_count/total_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "61e852dc-638b-4c51-84a0-172f56a9b081",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "749 1000 0.749\n"
     ]
    }
   ],
   "source": [
    "mmf_acc(ensemble.visual_bert, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0c63c45c-f60a-4a87-91b9-e3413f403dce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "751 1000 0.751\n"
     ]
    }
   ],
   "source": [
    "mmf_acc(ensemble.vilbert, 'test')"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cu110.m91",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cu110:m91"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
